{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baeb7375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Likely States Sequence (Sample): [0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0]\n",
      "State Probabilities (Sample - First 10):\n",
      "Fair Die: 0.756, Loaded Die: 0.244\n",
      "Fair Die: 0.457, Loaded Die: 0.543\n",
      "Fair Die: 0.458, Loaded Die: 0.542\n",
      "Fair Die: 0.396, Loaded Die: 0.604\n",
      "Fair Die: 0.399, Loaded Die: 0.601\n",
      "Fair Die: 0.477, Loaded Die: 0.523\n",
      "Fair Die: 0.472, Loaded Die: 0.528\n",
      "Fair Die: 0.477, Loaded Die: 0.523\n",
      "Fair Die: 0.491, Loaded Die: 0.509\n",
      "Fair Die: 0.474, Loaded Die: 0.526\n",
      "Mean State Probabilities (Sample):\n",
      "Fair Die: 0.495\n",
      "Loaded Die: 0.505\n",
      "Learned initial state probabilities (mean): [0.58519562 0.41480438]\n",
      "Learned initial state probabilities (std deviation): [0.47970883 0.47970883]\n",
      "Learned transition probabilities (mean):\n",
      " [[0.65628919 0.34371081]\n",
      " [0.42873138 0.57126862]]\n",
      "Learned transition probabilities (std deviation):\n",
      " [[0.12684398 0.12684398]\n",
      " [0.22101139 0.22101139]]\n",
      "Learned emission probabilities (mean):\n",
      " [[0.15628378 0.16197923 0.16235864 0.14094992 0.1773096  0.20111882]\n",
      " [0.10580112 0.13845276 0.14220134 0.18946625 0.12537834 0.29870019]]\n",
      "Learned emission probabilities (std deviation):\n",
      " [[0.06185492 0.02568596 0.04733356 0.06776048 0.04544137 0.13353482]\n",
      " [0.05623606 0.04166287 0.04442442 0.0971241  0.05398637 0.1192119 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def init_params(n_states, n_obs):\n",
    "    trans_probs = np.log(np.random.rand(n_states, n_states) + 1e-4)\n",
    "    emiss_probs = np.log(np.random.rand(n_states, n_obs) + 1e-4)\n",
    "    pi = np.log(np.random.rand(n_states) + 1e-4)\n",
    "\n",
    "    trans_probs -= logsumexp(trans_probs, axis=1, keepdims=True)\n",
    "    emiss_probs -= logsumexp(emiss_probs, axis=1, keepdims=True)\n",
    "    pi -= logsumexp(pi)\n",
    "    \n",
    "    return trans_probs, emiss_probs, pi\n",
    "\n",
    "def forward(observations, trans_probs, emiss_probs, pi):\n",
    "    '''Computes the forward probabilities in log.'''\n",
    "    T, N = len(observations), len(pi)\n",
    "    alpha = np.full((T, N), -np.inf)\n",
    "    alpha[0] = pi + emiss_probs[:, observations[0]]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            alpha[t, j] = logsumexp(alpha[t-1] + trans_probs[:, j]) + emiss_probs[j, observations[t]]\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def backward(observations, trans_probs, emiss_probs):\n",
    "    '''Computes the backward probabilities in log.'''\n",
    "    T, N = len(observations), trans_probs.shape[0]\n",
    "    beta = np.full((T, N), -np.inf)\n",
    "    beta[-1] = 0\n",
    "\n",
    "    for t in range(T-2, -1, -1):\n",
    "        for i in range(N):\n",
    "            beta[t, i] = logsumexp(trans_probs[i, :] + emiss_probs[:, observations[t+1]] + beta[t+1])\n",
    "\n",
    "    return beta\n",
    "\n",
    "def baum_welch(observations, n_states=2, n_obs=6, max_iter=100):\n",
    "    '''Applies the Baum-Welch algorithm to find the most likely parameters.'''\n",
    "    trans_probs, emiss_probs, pi = init_params(n_states, n_obs)\n",
    "    for _ in range(max_iter):\n",
    "        alpha = forward(observations, trans_probs, emiss_probs, pi)\n",
    "        beta = backward(observations, trans_probs, emiss_probs)\n",
    "        \n",
    "        # Expectation step for xi and gamma\n",
    "        xi = np.full((len(observations)-1, n_states, n_states), -np.inf)\n",
    "        for t in range(len(observations)-1):\n",
    "            for i in range(n_states):\n",
    "                for j in range(n_states):\n",
    "                    xi[t, i, j] = alpha[t, i] + trans_probs[i, j] + emiss_probs[j, observations[t+1]] + beta[t+1, j]\n",
    "            xi[t] -= logsumexp(xi[t])\n",
    "\n",
    "        gamma = alpha + beta\n",
    "        gamma -= logsumexp(gamma, axis=1, keepdims=True)\n",
    "        \n",
    "        # Maximization step\n",
    "        for i in range(n_states):\n",
    "            trans_probs[i] = logsumexp(xi[:-1, :, i], axis=0)\n",
    "            trans_probs[i] -= logsumexp(trans_probs[i])\n",
    "        for j in range(n_states):\n",
    "            for k in range(n_obs):\n",
    "                mask = observations == k\n",
    "                emiss_probs[j, k] = logsumexp(gamma[mask, j])\n",
    "            emiss_probs[j] -= logsumexp(emiss_probs[j])\n",
    "        pi = gamma[0] - logsumexp(gamma[0])\n",
    "\n",
    "    return np.exp(pi), np.exp(trans_probs), np.exp(emiss_probs)\n",
    "\n",
    "def forward_backward(observations, trans_probs, emiss_probs, pi):\n",
    "    alpha = forward(observations, trans_probs, emiss_probs, pi)\n",
    "    beta = backward(observations, trans_probs, emiss_probs)\n",
    "\n",
    "    gamma = np.exp(alpha + beta - logsumexp(alpha[-1]))\n",
    "    most_likely_states = np.argmax(gamma, axis=1)\n",
    "    \n",
    "    return most_likely_states, gamma\n",
    "\n",
    "def run_multiple_baum_welch(observations, n_states, n_obs, n_runs, max_iter):\n",
    "    '''Runs the Baum-Welch algorithm multiple times.'''\n",
    "    results = [baum_welch(observations, n_states, n_obs, max_iter) for _ in range(n_runs)]\n",
    "    results_pi, results_trans_probs, results_emiss_probs = zip(*results)\n",
    "\n",
    "    # Calculating statistics for initial, transition, and emission probabilities\n",
    "    mean_pi, std_pi = calc_stats(results_pi)\n",
    "    mean_trans_probs, std_trans_probs = calc_stats(results_trans_probs)\n",
    "    mean_emiss_probs, std_emiss_probs = calc_stats(results_emiss_probs)\n",
    "\n",
    "    return (mean_pi, std_pi), (mean_trans_probs, std_trans_probs), (mean_emiss_probs, std_emiss_probs)\n",
    "\n",
    "def calc_stats(results):\n",
    "    '''Calculates statistics (mean, standard deviation) for arrays of matrices.'''\n",
    "    mean = np.mean(results, axis=0)\n",
    "    std = np.std(results, axis=0)\n",
    "    return mean, std\n",
    "\n",
    "def analyze_observations(file_path, n_states=2, n_obs=6, n_runs=10, max_iter=50):\n",
    "    observations = np.loadtxt(file_path, dtype=int)\n",
    "\n",
    "    (stats_pi, stats_trans_probs, stats_emiss_probs) = run_multiple_baum_welch(\n",
    "        observations, n_states, n_obs, n_runs, max_iter\n",
    "    )\n",
    "    (mean_pi, std_pi), (mean_trans_probs, std_trans_probs), (mean_emiss_probs, std_emiss_probs) = stats_pi, stats_trans_probs, stats_emiss_probs\n",
    "\n",
    "    pi_sample, A_sample, B_sample = baum_welch(observations[:100], n_states=2, n_obs=6, max_iter=10)\n",
    "    most_likely_states_sample, state_probabilities_sample = forward_backward(observations[:100], A_sample, B_sample, pi_sample)\n",
    "    # Decide to switch dice\n",
    "    print(\"Most Likely States Sequence (Sample):\", most_likely_states_sample)\n",
    "    print(\"State Probabilities (Sample - First 10):\")\n",
    "    for prob in state_probabilities_sample[:10]:\n",
    "        print(f\"Fair Die: {prob[0]:.3f}, Loaded Die: {prob[1]:.3f}\")\n",
    "\n",
    "    # Calculating and printing mean state probabilities for the sample\n",
    "    mean_state_probabilities_sample = np.mean(state_probabilities_sample, axis=0)\n",
    "    print(\"Mean State Probabilities (Sample):\")\n",
    "    print(f\"Fair Die: {mean_state_probabilities_sample[0]:.3f}\")\n",
    "    print(f\"Loaded Die: {mean_state_probabilities_sample[1]:.3f}\")\n",
    "\n",
    "    print(\"Learned initial state probabilities (mean):\", mean_pi)\n",
    "    print(\"Learned initial state probabilities (std deviation):\", std_pi)\n",
    "    print(\"Learned transition probabilities (mean):\\n\", mean_trans_probs)\n",
    "    print(\"Learned transition probabilities (std deviation):\\n\", std_trans_probs)\n",
    "    print(\"Learned emission probabilities (mean):\\n\", mean_emiss_probs)\n",
    "    print(\"Learned emission probabilities (std deviation):\\n\", std_emiss_probs)\n",
    "\n",
    "analyze_observations(\"rolls.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
